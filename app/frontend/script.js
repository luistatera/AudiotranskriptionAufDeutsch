const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const statusEl = document.getElementById('status');
const transcriptEl = document.getElementById('transcription');

const urlConfig = new URL(window.location.href);
const apiBaseOverride = urlConfig.searchParams.get('api');
const DEFAULT_API_BASE = 'http://localhost:8000';
const API_BASE = apiBaseOverride || DEFAULT_API_BASE;
const TRANSCRIBE_URL = `${API_BASE.replace(/\/$/, '')}/transcribe`;

let mediaRecorder = null;
let mediaStream = null;
let isRecording = false;
let recordingInterval = null;

function setStatusText(text) {
  statusEl.textContent = text;
}

function appendTranscript(text) {
  if (!text) return;
  
  const current = transcriptEl.value.trim();
  transcriptEl.value = current ? `${current} ${text.trim()}` : text.trim();
  transcriptEl.scrollTop = transcriptEl.scrollHeight;
}

function resetState() {
  mediaRecorder = null;
  mediaStream = null;
  isRecording = false;
  if (recordingInterval) {
    clearInterval(recordingInterval);
    recordingInterval = null;
  }
}

async function uploadAudio(blob) {
  if (!blob || blob.size === 0) {
    console.warn('âš ï¸ No audio blob to upload or blob is empty');
    return;
  }
  
  console.log('ðŸŽµ === STARTING AUDIO UPLOAD ===');
  console.log('ðŸ“Š Audio blob details:', {
    size: blob.size,
    type: blob.type,
    lastModified: blob.lastModified || 'unknown'
  });
  
  const formData = new FormData();
  
  // Use appropriate filename based on blob type
  let filename = 'recording.webm';
  if (blob.type.includes('mp4')) {
    filename = 'recording.mp4';
  } else if (blob.type.includes('mpeg')) {
    filename = 'recording.mp3';
  } else if (blob.type.includes('wav')) {
    filename = 'recording.wav';
  }
  
  formData.append('audio', blob, filename);
  console.log('ðŸ“¦ Created FormData with filename:', filename);

  try {
    setStatusText('Processing audio...');
    console.log('ðŸš€ Sending POST request to:', TRANSCRIBE_URL);
    
    const startTime = Date.now();
    const response = await fetch(TRANSCRIBE_URL, {
      method: 'POST',
      body: formData,
    });
    const requestTime = Date.now() - startTime;

    console.log('ðŸ“¡ Response received:', {
      status: response.status,
      statusText: response.statusText,
      contentType: response.headers.get('content-type'),
      requestTime: requestTime + 'ms'
    });

    if (!response.ok) {
      console.error('âŒ Request failed with status:', response.status);
      const errorData = await response.json().catch(() => ({}));
      console.error('âŒ Error response data:', errorData);
      throw new Error(errorData.detail || `HTTP ${response.status}`);
    }

    console.log('âœ… Request successful, parsing JSON...');
    const data = await response.json();
    console.log('ðŸ“‹ Response data:', data);
    
    if (data.text) {
      console.log('âœ… Transcription successful! Text:', data.text);
      console.log('ðŸ“ Appending to transcript area...');
      appendTranscript(data.text);
      console.log('ðŸŽµ === AUDIO UPLOAD COMPLETED SUCCESSFULLY ===');
    } else {
      console.warn('âš ï¸ No text field in response data');
    }
    
    setStatusText(isRecording ? 'Recording' : 'Idle');
  } catch (error) {
    console.error('âŒ === AUDIO UPLOAD FAILED ===');
    console.error('âŒ Error details:', error);
    setStatusText(`Error: ${error.message}`);
  }
}

async function recordChunk() {
  if (!isRecording || !mediaStream) {
    console.warn('âš ï¸ Cannot record: isRecording =', isRecording, ', mediaStream =', !!mediaStream);
    return;
  }
  
  console.log('ðŸŽ™ï¸ === STARTING NEW RECORDING CHUNK ===');
  
  // Try different audio formats for better compatibility
  let options = {};
  const formats = [
    'audio/mp4',
    'audio/mpeg',
    'audio/wav',
    'audio/webm;codecs=opus',
    'audio/webm'
  ];
  
  for (const format of formats) {
    if (MediaRecorder.isTypeSupported(format)) {
      options = { mimeType: format };
      console.log('âœ… Using supported format:', format);
      break;
    }
  }
  
  if (!options.mimeType) {
    console.log('âš ï¸ No specific format supported, using default');
  }
  
  // Create a fresh MediaRecorder for each chunk
  mediaRecorder = new MediaRecorder(mediaStream, options);
  
  const chunks = [];
  
  mediaRecorder.ondataavailable = (event) => {
    console.log('ðŸ“Š Data available event, size:', event.data.size, 'bytes');
    if (event.data.size > 0) {
      chunks.push(event.data);
      console.log('âœ… Added chunk, total chunks:', chunks.length);
    } else {
      console.warn('âš ï¸ Received empty data chunk');
    }
  };
  
  mediaRecorder.onstop = () => {
    console.log('ðŸ›‘ MediaRecorder stopped, chunks count:', chunks.length);
    if (chunks.length > 0) {
      // Use the same type as the MediaRecorder
      const blob = new Blob(chunks, { type: mediaRecorder.mimeType });
      console.log('ðŸ“¦ Created blob:', {
        size: blob.size,
        type: blob.type,
        mimeType: mediaRecorder.mimeType
      });
      uploadAudio(blob);
    } else {
      console.warn('âš ï¸ No chunks to upload - recording may have failed');
    }
    
    // Clear the reference to help with cleanup
    mediaRecorder = null;
  };
  
  mediaRecorder.onerror = (event) => {
    console.error('MediaRecorder error:', event.error);
  };
  
  // Record for exactly 3 seconds (faster transcription)
  console.log('â–¶ï¸ Starting MediaRecorder...');
  mediaRecorder.start();
  console.log('â±ï¸ Recording will stop automatically after 3 seconds');
  
  setTimeout(() => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('â° 3 seconds elapsed, stopping recording...');
      mediaRecorder.stop();
    } else {
      console.warn('âš ï¸ MediaRecorder not in recording state after 3 seconds:', mediaRecorder?.state);
    }
  }, 3000);
}

async function startRecording() {
  if (isRecording) return;
  
  setStatusText('Requesting microphone...');
  
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        channelCount: 1,
        sampleRate: 16000,
        echoCancellation: true,
        noiseSuppression: true
      }
    });
  } catch (err) {
    console.error('Microphone access denied:', err);
    setStatusText('Error: Microphone access denied');
    return;
  }

  isRecording = true;
  startBtn.disabled = true;
  stopBtn.disabled = false;
  setStatusText('Recording');
  
  // Record first chunk immediately
  recordChunk();
  
  // Then record a new chunk every 4 seconds (1 second gap for cleanup)
  recordingInterval = setInterval(() => {
    // Add a small delay to ensure previous MediaRecorder is fully cleaned up
    setTimeout(recordChunk, 1000);
  }, 4000);
}

function stopRecording() {
  console.log('Stop recording requested');
  
  // First, capture any current recording before stopping
  if (mediaRecorder && mediaRecorder.state === 'recording') {
    console.log('Stopping current recording to capture final chunk');
    mediaRecorder.stop(); // This will trigger onstop and upload the final chunk
    
    // Give it a moment to process the final chunk
    setTimeout(() => {
      finishStopRecording();
    }, 500);
  } else {
    finishStopRecording();
  }
}

function finishStopRecording() {
  console.log('Finishing stop recording process');
  isRecording = false;
  startBtn.disabled = false;
  stopBtn.disabled = true;
  
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
  }
  
  resetState();
  setStatusText('Idle');
}

// Event listeners
startBtn.addEventListener('click', startRecording);
stopBtn.addEventListener('click', stopRecording);

// Check browser support
if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
  setStatusText('Error: Audio recording not supported');
  startBtn.disabled = true;
} else if (!window.MediaRecorder) {
  setStatusText('Error: MediaRecorder not supported');
  startBtn.disabled = true;
} else {
  setStatusText('Ready');
}
